{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Representación y Formación de imagenes<a class=\"tocSkip\">\n",
    "## TRATAMIENTO DE SEÑALES <a class=\"tocSkip\">\n",
    "### Ingenieria Electrónica <a class=\"tocSkip\">\n",
    "### Universidad Popular del Cesar <a class=\"tocSkip\">\n",
    "### Prof.: Jose Ramón Iglesias Gamarra - [https://github.com/joseramoniglesias/](https://github.com/joseramoniglesias/) <a class=\"tocSkip\">\n",
    "  **joseiglesias@unicesar.edu.co**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Métricas globales y operaciones básicas DIP"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (3.0, 3.0)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## En el Directorio scr están las imágenes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image=cv2.imread('lenna.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img_max = np.max(input_image)\n",
    "img_min = np.min(input_image)\n",
    "print(\"Dimensiones de la imagen: \", input_image.shape)\n",
    "print(\"Tipo de dato: \", input_image.dtype)\n",
    "print(\"Nivel máximo de intensidad: \", img_max)\n",
    "print(\"Nivel mínimo de intensidad: \", img_min)\n",
    "plt.imshow(input_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas globales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brillo\n",
    "Nivel medio de grises en una imagen.\n",
    "\n",
    "$B=\\frac{1}{N\\times M}\\sum_{i=0}^{N-1}\\sum_{j=0}^{M-1}f(i,j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness(img): # Para una imagen en escala de grises\n",
    "    return np.average(img)\n",
    "\n",
    "def adjust_brightness(img, adjustment): # Aumentar o disminuir el brillo de una imagen en escala de grises\n",
    "    if adjustment != 0:\n",
    "        return np.clip((img.astype(np.int16)+adjustment), 0, 255)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_input = brightness(input_image)\n",
    "print(\"Brillo imagen original: \", B_input)\n",
    "plt.imshow(input_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_adjust = 100\n",
    "bright_image = adjust_brightness(input_image, brightness_adjust)\n",
    "print(f\"Brillo imagen ({brightness_adjust}): \", brightness(bright_image))\n",
    "plt.imshow(bright_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_adjust = -100\n",
    "dim_image = adjust_brightness(input_image, brightness_adjust)\n",
    "print(f\"Brillo imagen ({brightness_adjust})): \", brightness(dim_image))\n",
    "plt.imshow(dim_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraste\n",
    "Variación del nivel de grises en una imagen.\n",
    "\n",
    "$C=\\sqrt{\\frac{1}{N\\times M}\\sum_{i=0}^{N-1}\\sum_{j=0}^{M-1}[f(i,j)-B]^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(img): # Para una imagen en escala de grises\n",
    "    return np.std(img)\n",
    "\n",
    "def contrast_adjustment(img, adjustment): # Ajuste de contraste para una imagen en escala de grises\n",
    "    return np.uint8(np.clip((adjustment * img), 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_input = contrast(input_image)\n",
    "print(\"Contraste imagen original: \", C_input)\n",
    "plt.imshow(input_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.3\n",
    "high_contrast = contrast_adjustment(input_image, alpha)\n",
    "print(f\"Contraste imagen {alpha}: \", contrast(high_contrast))\n",
    "plt.imshow(high_contrast, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "low_contrast = contrast_adjustment(input_image, alpha)\n",
    "print(f\"Contraste imagen {alpha}: \", contrast(low_contrast))\n",
    "plt.imshow(low_contrast, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nitidez\n",
    "Respuesta en nivel de gris de una imagen ante cambios bruscos en la iluminación de la escena captada.\n",
    "\n",
    "<img src=\"src/nitidez.png\" alt=\"Comparación alta nitidez vs. baja nitidez\" style=\"height: 350px; width:700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeficientes = np.array([[0, 1, 0],\n",
    "                         [1, -5, 1],\n",
    "                         [0, 1, 0]])*-1\n",
    "sharpened = cv2.filter2D(input_image, 0, coeficientes)\n",
    "_, ax = plt.subplots(1, 2, squeeze=True, **{'figsize':[20.0, 6.0]})\n",
    "ax[0].imshow(input_image, cmap='gray')\n",
    "ax[1].imshow(sharpened, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma\n",
    "\n",
    "Un histograma es una gráfica en donde se muestra la frecuencia con las que aparecen los distintos niveles de intensidad de una imagen a escala de grises, normalmente el nivel de intensidad está en el rango de 0 a 255, en donde el valor 0 representa los color negro y 255 el color blanco, utilizando el histograma de una imagen podemos modificar sus características, por ejemplo, el brillo y contraste, existen además otras aplicaciones que veremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cv2.calcHist(images=[input_image], channels=[0], mask = None, histSize=[img_max], ranges=[img_min, img_max])\n",
    "plt.title('Imagen Original')\n",
    "plt.plot(hist, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_image = bright_image.astype(np.uint8)\n",
    "hist = cv2.calcHist(images=[bright_image], channels=[0], mask = None, histSize=[np.max(bright_image)], ranges=[np.min(bright_image), np.max(bright_image)])\n",
    "plt.title('Imagen alto brillo')\n",
    "plt.plot(hist, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_image = dim_image.astype(np.uint8)\n",
    "hist = cv2.calcHist(images=[dim_image], channels=[0], mask = None, histSize=[np.max(dim_image)], ranges=[np.min(dim_image), np.max(dim_image)])\n",
    "plt.title('Imagen bajo brillo')\n",
    "plt.plot(hist[1:], color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_contrast = low_contrast.astype(np.uint8)\n",
    "hist = cv2.calcHist(images=[low_contrast], channels=[0], mask = None, histSize=[np.max(low_contrast)], ranges=[np.min(low_contrast), np.max(low_contrast)])\n",
    "plt.title('Imagen bajo contraste')\n",
    "plt.plot(hist, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones de una imagen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones puntuales\n",
    "El resultado de aplicarlas a un píxel depende únicamente del valor de intensidad de ese píxel.\n",
    "\n",
    "Ya exploramos la **multiplicación por una constante** y sus efectos en el contraste y la **suma o resta de una constante** y sus efectos en el brillo de la imagen.\n",
    "\n",
    "También se consideran operaciones como la umbralización: convertir una imagen en escala de grises a una imagen binaria (0 o 1) utilizando un umbral para la decisión, en la medida en que el umbral sea más alto, la imagen resultante será mayormente negra (0), y en el caso contrario será mayormente blanca (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50\n",
    "img_umbral = np.uint8(input_image>threshold)\n",
    "plt.title(f'Imagen umbralizada ({threshold})')\n",
    "plt.imshow(img_umbral, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img_umbral)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umbralización adaptativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T, threshInv) = cv2.threshold(input_image, 0, 255, cv2.THRESH_OTSU)\n",
    "plt.title(f'Imagen umbralizada ({T})')\n",
    "plt.imshow(threshInv, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = cv2.adaptiveThreshold(input_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 7, 10)\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagen inversa: equivalente a un negativo fotográfico. Ver el ejemplo del impacto en una mamografía.\n",
    "\n",
    "<img src=\"https://github.com/MoraRubio/dip-uam/raw/main/src/inversa.png\" alt=\"Imagen de mamografía y su inversa\" style=\"height: 350px; width:700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inversa = img_max - input_image\n",
    "plt.title(f'Imagen inversa')\n",
    "plt.imshow(img_inversa, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_orig = cv2.calcHist(images=[input_image], channels=[0], mask = None, histSize=[img_max], ranges=[img_min, img_max])\n",
    "hist_inverse = cv2.calcHist(images=[img_inversa], channels=[0], mask = None, histSize=[np.max(img_inversa)], ranges=[np.min(img_inversa), np.max(img_inversa)])\n",
    "\n",
    "_, ax = plt.subplots(1, 2, squeeze=True, **{'figsize':[20.0, 6.0]})\n",
    "ax[0].plot(hist_orig, color='gray')\n",
    "ax[1].plot(hist_inverse, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecualización de histogramas: busca obtener una distribución uniforme de los distintos niveles de intensidad, esta técnica es muy utilizada para mejorar el contraste de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_eq_img = cv2.equalizeHist(input_image)\n",
    "plt.title(f'Imagen con ecualización de histograma')\n",
    "plt.imshow(hist_eq_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_orig = cv2.calcHist(images=[input_image], channels=[0], mask = None, histSize=[img_max], ranges=[img_min, img_max])\n",
    "hist_eq = cv2.calcHist(images=[hist_eq_img], channels=[0], mask = None, histSize=[np.max(hist_eq_img)], ranges=[np.min(hist_eq_img), np.max(hist_eq_img)])\n",
    "\n",
    "_, ax = plt.subplots(1, 2, squeeze=True, **{'figsize':[20.0, 6.0]})\n",
    "ax[0].plot(hist_orig, color='gray')\n",
    "ax[1].plot(hist_eq, color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiar el número de bits en el que está representado una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_bits(img, k_orig, k_new):\n",
    "    a=np.power(2, k_orig-k_new)\n",
    "    k_img=np.zeros(img.shape)\n",
    "    for i in range(np.power(2, k_new)):\n",
    "        val=np.full_like(k_img,i)\n",
    "        for j in range(a):\n",
    "            k_img+=(img==(j+a*i))*val\n",
    "    return k_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_img = k_bits(input_image, 8, 6).astype(np.uint8)\n",
    "plt.imshow(k_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(k_img, return_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir una imagen en términos de bits [(Kaggle)](https://www.kaggle.com/code/siddheshmahajan/opencv-basics-bit-plane-slicing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_binary(num):\n",
    "    binary_num = [int(i) for i in list('{0:0b}'.format(num))]\n",
    "    for j in range(8 - len(binary_num)):\n",
    "        binary_num.insert(0,0)        \n",
    "    return binary_num\n",
    "\n",
    "def conv_decimal(listt):\n",
    "    x = 0\n",
    "    for i in range(8):\n",
    "        x = x + int(listt[i])*(2**(7-i))\n",
    "    return x\n",
    "\n",
    "def discriminate_bit(bit,img):\n",
    "    shape = img.shape\n",
    "    z = np.zeros(shape)\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            x = cov_binary(img[i][j])\n",
    "            for k in range(8):\n",
    "                if k == bit:\n",
    "                    x[k] = x[k]\n",
    "                else:\n",
    "                    x[k] = 0\n",
    "            x1 = conv_decimal(x)\n",
    "            z[i][j] = x1\n",
    "    return z\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "for i in range(1,9):\n",
    "    fig.add_subplot(4,2,i)\n",
    "    plt.imshow(discriminate_bit(i-1,input_image), cmap='gray')\n",
    "\n",
    "plt.show(block=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones geométricas\n",
    "\n",
    "En las operaciones geométricas la posición de cada píxel en la imagen resultado depende de su posición en la imagen original.\n",
    "\n",
    "Abarca operaciones como:\n",
    "- Zoom\n",
    "- Rotación\n",
    "- Traslación\n",
    "- Warping o distorsión.\n",
    "\n",
    "Un caso particular es el redimensionamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_down = 0.2\n",
    "res_inter_nearest = cv2.resize(input_image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_NEAREST)\n",
    "res_inter_linear = cv2.resize(input_image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_LINEAR)\n",
    "res_inter_area = cv2.resize(input_image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_AREA)\n",
    "res_inter_cubic = cv2.resize(input_image, None, fx= scale_down, fy= scale_down, interpolation= cv2.INTER_CUBIC)\n",
    "\n",
    "_, ax = plt.subplots(2, 2, **{'figsize':[10.0, 8.0]})\n",
    "ax[0,0].imshow(res_inter_nearest, cmap='gray')\n",
    "ax[0,0].title.set_text('Interpolation nearest')\n",
    "ax[0,1].imshow(res_inter_linear, cmap='gray')\n",
    "ax[0,1].title.set_text('Interpolation linear')\n",
    "ax[1,0].imshow(res_inter_area, cmap='gray')\n",
    "ax[1,0].title.set_text('Interpolation area')\n",
    "ax[1,1].imshow(res_inter_cubic, cmap='gray')\n",
    "ax[1,1].title.set_text('Interpolation cubic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_up = 2.5\n",
    "res_inter_nearest = cv2.resize(input_image, None, fx= scale_up, fy= scale_up, interpolation= cv2.INTER_NEAREST)\n",
    "res_inter_linear = cv2.resize(input_image, None, fx= scale_up, fy= scale_up, interpolation= cv2.INTER_LINEAR)\n",
    "res_inter_area = cv2.resize(input_image, None, fx= scale_up, fy= scale_up, interpolation= cv2.INTER_AREA)\n",
    "res_inter_cubic = cv2.resize(input_image, None, fx= scale_up, fy= scale_up, interpolation= cv2.INTER_CUBIC)\n",
    "\n",
    "_, ax = plt.subplots(2, 2, **{'figsize':[10.0, 8.0]})\n",
    "ax[0,0].imshow(res_inter_nearest, cmap='gray')\n",
    "ax[0,0].title.set_text('Interpolation nearest')\n",
    "ax[0,1].imshow(res_inter_linear, cmap='gray')\n",
    "ax[0,1].title.set_text('Interpolation linear')\n",
    "ax[1,0].imshow(res_inter_area, cmap='gray')\n",
    "ax[1,0].title.set_text('Interpolation area')\n",
    "ax[1,1].imshow(res_inter_cubic, cmap='gray')\n",
    "ax[1,1].title.set_text('Interpolation cubic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(res_inter_nearest == res_inter_linear).all()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones locales\n",
    "\n",
    "La imagen se transforma en función de los niveles de gris de cada píxel considerado y de los de su entorno (filtros o kernels). Pueden ser:\n",
    "- Lineales\n",
    "- No lineales\n",
    "    - Estadísticas\n",
    "    - Analíticas\n",
    "        - Media geométrica\n",
    "        - Media armónica\n",
    "- Morfológicas\n",
    "    - Erosión\n",
    "    - Dilatación\n",
    "    - Adelgazamiento y esqueletización\n",
    "    - Opening\n",
    "    - Closing\n",
    "\n",
    "### Operaciones globales\n",
    "\n",
    "La imagen se transforma como una unidad, sin considerar los píxeles de forma individual. Generalmente representa un cambio de dominio.\n",
    "\n",
    "Entre las más empleadas:\n",
    "- Transformada de Fourier\n",
    "- Transformada de Hadamard-Walsh\n",
    "- Transformada de Karhunen-Lòeve\n",
    "- Transformada discreta del coseno\n",
    "- Transformada de Hough\n",
    "- Cambio entre espacios de color"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Copyright**\n",
    "\n",
    "The notebooks are provided as [Open Educational Resource](https://de.wikipedia.org/wiki/Open_Educational_Resources). Feel free to use the notebooks for your own educational purposes. The text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/), the code of the IPython examples under the [MIT license](https://opensource.org/licenses/MIT)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ee78bf6d3c55ab8d976b00cd533f0c8b1f102162595d6dc238528d9a3be5ad3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
